# @package _global_

# to execute this experiment run:
# python train.py experiment=train_tsdf_one_frame

defaults:
  - override /data: gpu_one_scene_seqs
  - override /model: gen_nerf
  - override /callbacks: default
  - override /logger: null
  - override /trainer: ddp
  - override /paths: cluster

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ['dev', 'cluster', 'one_scene_seqs', 'only_tsdf']

seed: 0

trainer:
  devices: 1
  num_nodes: 1
  min_epochs: 200
  max_epochs: 200
  log_every_n_steps: 5
  check_val_every_n_epoch: 25
  #gradient_clip_val: 0.5

model:
  optimizer:
    lr: 0.0001
    weight_decay: 0.0001
  scheduler:
    step_size: 300
    gamma: 0.1
  compile: false

  encoder:
    use_spatial: false
    spatial:
      backbone: 'resnet34'
      use_first_pool: true
    use_pointnet: true
    pointnet:
      num_sparse_points: 512
      n_blocks: 4
      c_dim: 64
      plane_resolution: 128
      unet_kwargs:
        depth: 3

sampling_mode: 'frustum'
ray:
  num_rays: 100
  N: 20
  M: 8
  d_min: 0.07
  delta: 0.1
  sigma: 0.1
frustum:
  N: 512
  M: 1
  sigma: 0.0
  d_min: 0.5
  d_max: 2.0

  mlp:
    d_out_sem: 1
    d_out_geo: 64
    n_blocks: 5
  
  use_code: True
  code:
    num_freqs: 6 
    freq_factor: 0.5
    include_input: True

  tsdf_loss:
    weight: 1.0
    log_transform: True
    log_transform_shift: 15.0
    log_transform_beta: 10.0
    use_smoothness_reg: False
    smoothness_reg:
      weight: 0.1
      k: 3
    use_eikonal_reg: False
    eikonal_reg:
      weight: 0.01

data:
  batch_size_train: 1  # Needs to be divisible by the number of devices
  dataset_type: 'sequences'  # 'sequences' or 'frame' or 'scene'
  sequence_amount_train: 0.1  # controls the number of sequences scene-denpendently
                        # num_sequences = sequence_amount * (num_scene_frames / sequence_length)
  sequence_amount_val: 0.1
  sequence_amount_test: 0.1
  sequence_length: 300  # number of raw frames to be considered as one sequence
  sequence_locations: 'free' # 'free' or 'fixed' or 'evenly_spaced'
  sequence_order: 'random'  # 'random' or 'sorted'
  num_frames_train: 7  # number of frames to select from a sequence (-1 = sequence_length)
  num_frames_val: 7
  num_frames_test: 7
  frame_locations: 'evenly_spaced'  # 'free' or 'evenly_spaced'
  frame_order: 'random'  # 'random' or 'sorted'
  voxel_size: .04
  voxel_dim_train: [200, 250, 64] # [160, 160, 64]
  voxel_dim_val: [200, 250, 64] # [256, 256, 96]
  voxel_dim_test: [200, 250, 64] # [416, 416, 128

  # debug:
  random_rotation_3d: false
  random_translation_3d: false
  pad_xy_3d: 0.0
  pad_z_3d: 0.0

logger:
  wandb:
    #name: "train_tsdf_one_scene_seqs1_framesN"
    job_type: "experimental" # train / eval / test / experimental / sweep
    tags: ${tags}
    
    # debug:
    entity: "generalizable-nerfs"